{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "import scipy.signal.spectral as sss\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def batch2image(signal_batch, sampling_rate, pooling_size, process_type='wavelet'):\n",
    "    \"\"\"\n",
    "    批数据转换成图片\n",
    "    :signal_batch:\n",
    "    :sampling_rate:\n",
    "    :pooling_size:\n",
    "    :process_type:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num, dim = np.shape(signal_batch)\n",
    "    batch_set = []\n",
    "    if process_type == 'wavelet':\n",
    "        for i in range(num):\n",
    "            image, _ = wavelet2image(signal_batch[i, :], sampling_rate)\n",
    "            batch_set.append(image)\n",
    "    elif process_type == 'stft':\n",
    "        for i in range(num):\n",
    "            image, _ = stft2image(signal_batch[i, :], sampling_rate)\n",
    "            batch_set.append(image)\n",
    "    else:\n",
    "        raise KeyError(\"process_type must be wavelet of stft!\")\n",
    "    batch_set = np.array(batch_set)\n",
    "    batch_set = image_downsampling(batch_set, pooling_size, form='avg_pooling')\n",
    "\n",
    "    return batch_set\n",
    "\n",
    "def wavelet2image(signal, sampling_rate, freq_dim_scale=256, wavelet_name='morl'):\n",
    "\n",
    "    \"\"\"\n",
    "    小波图像\n",
    "    :param signal: 1D temporal sequence\n",
    "    :param sampling_rate: sampling rate for the sequence  定义了每秒从连续信号中提取并组成离散信号的采样个数\n",
    "    :param freq_dim_scale: frequency resolution  目的是避免信号混淆保证高频信号不被歪曲成低频信号\n",
    "    :param wavelet_name: wavelet name for CWT, here we have 'morl', 'gaus', 'cmor',...\n",
    "    :return: time-freq image and its reciprocal frequencies  时频图像及其倒数频率\n",
    "    \"\"\"\n",
    "\n",
    "    freq_centre = pywt.central_frequency(wavelet_name)            # 所选小波的中心频率\n",
    "    cparam = 2 * freq_centre * freq_dim_scale\n",
    "    scales = cparam / np.arange(1, freq_dim_scale + 1, 1)         # 获取小波基函数的尺度参数 a 的倒数\n",
    "    [cwt_matrix, frequencies] = pywt.cwt(signal, scales, wavelet_name, 1.0 / sampling_rate)\n",
    "\n",
    "    return abs(cwt_matrix), frequencies\n",
    "\n",
    "def stft2image(signal, sampling_rate, freq_dim_scale=256, window_name=('gaussian', 3.0)):\n",
    "\n",
    "    \"\"\"\n",
    "    :param signal: signal input for stft\n",
    "    :param sampling_rate:\n",
    "    :param window_name: (gaussian,3), hann, hamming, etc.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Window types:\n",
    "\n",
    "        `boxcar`, `triang`, `blackman`, `hamming`, `hann`, `bartlett`,\n",
    "        `flattop`, `parzen`, `bohman`, `blackmanharris`, `nuttall`,\n",
    "        `barthann`, `kaiser` (needs beta), `gaussian` (needs standard\n",
    "        deviation), `general_gaussian` (needs power, width), `slepian`\n",
    "        (needs width), `dpss` (needs normalized half-bandwidth),\n",
    "        `chebwin` (needs attenuation), `exponential` (needs decay scale),\n",
    "        `tukey` (needs taper fraction)\n",
    "\n",
    "    :return: time-freq image and its frequencies\n",
    "    \"\"\"\n",
    "\n",
    "    f, t, Zxx = sss.stft(signal, fs=sampling_rate, window=window_name, nperseg=freq_dim_scale)\n",
    "\n",
    "    return Zxx, f\n",
    "\n",
    "def image_downsampling(image_set, pooling_size=2, form='max_pooling', axis=None):\n",
    "\n",
    "    \"\"\"\n",
    "    :param image_set: input image with large size\n",
    "    :param pooling_size: down-sampling rate\n",
    "    :param form: 'max_pooling' or 'avg_pooling'\n",
    "    :param axis: if axis is not None, it means that the image will be down-sampled\n",
    "                 just within it row(axis=0) or column(axis=1).\n",
    "    :return: image has been down-sampled\n",
    "    \"\"\"\n",
    "\n",
    "    num, time_dim, freq_dim = np.shape(image_set)[0], np.shape(image_set)[1], np.shape(image_set)[2]\n",
    "    image_set = image_set.reshape(num, time_dim, freq_dim, 1)\n",
    "    im_input = tf.placeholder(dtype=tf.float32, shape=[num, time_dim, freq_dim, 1])\n",
    "    kernel_size = [pooling_size, 2*pooling_size]\n",
    "    if axis == 0:\n",
    "        kernel_size = [pooling_size, 1]\n",
    "    elif axis == 1:\n",
    "        kernel_size = [1, pooling_size]\n",
    "\n",
    "    with tf.device('/cpu:0'):\n",
    "        pooling_max = tf.contrib.slim.max_pool2d(im_input, kernel_size=kernel_size, stride=kernel_size)\n",
    "        pooling_avg = tf.contrib.slim.avg_pool2d(im_input, kernel_size=kernel_size, stride=kernel_size)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        down_sampling_im = sess.run(fetches=pooling_max, feed_dict={im_input: image_set})\n",
    "        if form == 'avg_pooling':\n",
    "            down_sampling_im = sess.run(fetches=pooling_avg, feed_dict={im_input: image_set})\n",
    "\n",
    "    return down_sampling_im\n",
    "\n",
    "def get_batch(filename, window_size=512, batch_size=1000, stride=180):\n",
    "    data = np.loadtxt(filename)\n",
    "    print(data.shape)\n",
    "    start = 0\n",
    "    cnt = 0\n",
    "    batch_data = []\n",
    "    while start + window_size < data.shape[0] and cnt < batch_size:\n",
    "        batch_data.append(data[start: start + window_size])\n",
    "        start = start + stride + 1\n",
    "        cnt += 1\n",
    "    batch_data = np.array(batch_data)\n",
    "    return batch_data\n",
    "\n",
    "for root, dirs, files in os.walk(\"./datas/origin\"):\n",
    "    print(files)\n",
    "\n",
    "output_path = './datas/image'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "    \n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    #print(1)\n",
    "    print(\"processing %s\" % file)\n",
    "    c = file.split('_')[0] if \"normal\" in file else file.split('_')[3]\n",
    "    #label = \"{}_{}\".format(c, i)  # 师兄写的\n",
    "    label = c.split('.')[0]  # 我写的\n",
    "    print(label)\n",
    "    file_path = os.path.join(root, file)\n",
    "    print(file_path)\n",
    "    signal = get_batch(filename=file_path, batch_size=2000)\n",
    "    batch_image = batch2image(signal, sampling_rate=1, pooling_size=4)\n",
    "    print(\"saving %s/%s.npy, shape %s\" % (output_path, label, batch_image.shape))\n",
    "    np.save(\"%s/%s.npy\" % (output_path, label), batch_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_dataset1(select):\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "    i=0\n",
    "    for elem in select:\n",
    "        print(elem[0])\n",
    "#        sig = df[elem[0]]\n",
    "      #  print(len(sig))\n",
    "        if elem[1] == 0:\n",
    "            sig =np.load(\"./datas/image/IF.npy\")\n",
    "        elif elem[1] == 1:\n",
    "            sig =np.load(\"./datas/image/OF.npy\")\n",
    "        else:\n",
    "            sig =np.load(\"./datas/image/BF.npy\")\n",
    "      #  i = i+1   \n",
    "        label = elem[1]\n",
    "        x = sig\n",
    "        print(x.shape)\n",
    "      #  print(x.shape[0])\n",
    "        x_all.append(x)\n",
    "        y = [[label] for _ in range(x.shape[0])]\n",
    "        y_all.append(y)\n",
    "    x_merge = np.vstack(x_all)  # 在竖直方向上堆叠\n",
    "    y_merge = np.vstack(y_all)\n",
    "    return x_merge, y_merge\n",
    "def creat_dataset2(select):\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "    i=0\n",
    "    for elem in select:\n",
    "        print(elem[0])\n",
    "#        sig = df[elem[0]]\n",
    "      #  print(len(sig))\n",
    "        if elem[1] == 0:\n",
    "            sig =np.load(\"./datas/image/IO.npy\")\n",
    "        elif elem[1] == 1:\n",
    "            sig =np.load(\"./datas/image/IB.npy\")\n",
    "        \n",
    "        elif elem[1] == 2:\n",
    "            sig =np.load(\"./datas/image/OB.npy\")\n",
    "        else:\n",
    "            sig =np.load(\"./datas/image/IOB.npy\")\n",
    "      #  i = i+1   \n",
    "        label = elem[1]\n",
    "        x = sig\n",
    "        print(x.shape)\n",
    "      #  print(x.shape[0])\n",
    "        x_all.append(x)\n",
    "        y = [[label] for _ in range(x.shape[0])]\n",
    "        y_all.append(y)\n",
    "    x_merge = np.vstack(x_all)\n",
    "    y_merge = np.vstack(y_all)\n",
    "    return x_merge, y_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = [('Inner',0), ('Outter', 1), ('Ball', 2)]\n",
    "data_test  = [('IO',0), ('IB', 1), ('OB', 2),('IOB', 3)]\n",
    "\n",
    "x_train, y_train = creat_dataset1(select=data_train)\n",
    "x_test, y_test = creat_dataset2(select=data_test)\n",
    "\n",
    "np.save('./data/train/x_trian', x_train)\n",
    "np.save('./data/train/y_train', y_train)\n",
    "np.save('./data/test/x_test', x_test)\n",
    "np.save('./data/test/y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = np.random.randint(0, 2000,1)\n",
    "idx2 = np.random.randint(2000, 4000,1)\n",
    "idx3 = np.random.randint(4000, 6000,1)\n",
    "idx4 = np.random.randint(6000, 8000,1)\n",
    "\n",
    "x_train =np.load(\"./datas/train/x_train.npy\")\n",
    "x_test =np.load(\"./datas/test/x_test.npy\")\n",
    "\n",
    "IF = x_train[idx1]\n",
    "OF = x_train[idx2]\n",
    "BF = x_train[idx3]\n",
    "\n",
    "IO = x_test[idx1]\n",
    "IB = x_test[idx2]\n",
    "OB = x_test[idx3]\n",
    "IOB = x_test[idx4]\n",
    "#print(IO.shape)\n",
    "IF = IF.reshape(64,64)  \n",
    "OF = OF.reshape(64,64) \n",
    "BF = BF.reshape(64,64) \n",
    "\n",
    "IO = IO.reshape(64,64)   \n",
    "IB = IB.reshape(64,64)  \n",
    "OB = OB.reshape(64,64)  \n",
    "IOB = IOB.reshape(64,64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot \n",
    "#import cv2 as cv\n",
    "# cv.imshow('GrayImage', IO)\n",
    "\n",
    "# GDATA = rgb2gray(IO)\n",
    "# pyplot.imshow(GDATA)\n",
    "plt.imshow(IF, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot \n",
    "#import cv2 as cv\n",
    "# cv.imshow('GrayImage', IO)\n",
    "\n",
    "# GDATA = rgb2gray(IO)\n",
    "# pyplot.imshow(GDATA)\n",
    "plt.imshow(OF, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(BF, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IO, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IB, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(OB, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(IOB, cmap = plt.get_cmap('gray'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
